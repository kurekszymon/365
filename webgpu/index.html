<!doctype html>

<html>

<head>
  <meta charset="utf-8">
  <title>WebGPU Life</title>
</head>

<body>
  <canvas width="512" height="512"></canvas>
  <script type="module">
    const canvas = document.querySelector("canvas");


    // setup webgpu
    if (!navigator.gpu) {
      throw new Error("WebGPU not supported on this browser.");
    }

    const adapter = await navigator.gpu.requestAdapter();
    if (!adapter) {
      throw new Error("No appropriate GPUAdapter found.");
    }

    const device = await adapter.requestDevice();


    // draw
    const encoder = device.createCommandEncoder(); // interface for recording gpu commands
    const context = canvas.getContext("webgpu");
    const canvasFormat = navigator.gpu.getPreferredCanvasFormat();

    context.configure({
      device: device,
      format: canvasFormat,
    });

    const pass = encoder.beginRenderPass({
      colorAttachments: [{
        view: context.getCurrentTexture().createView(),
        loadOp: "clear", // indicates what to do on texture load
        clearValue: [0, 0.5, 0, 1], //  pass colors as arra7 shorthand
        clearValue: { r: 0, g: 0, b: 0.4, a: 1 }, // pass colors as an object
        storeOp: "store", // what to do with results of drawings
      }]
    });

    // DRAWING GEOMETRY

    const vertices = new Float32Array([
      //   X,    Y,
      -0.8, -0.8, // Triangle 1 (Blue)
      0.8, -0.8,
      0.8, 0.8,

      -0.8, -0.8, // Triangle 2 (Red)
      0.8, 0.8,
      -0.8, 0.8,
    ]);

    const vertexBuffer = device.createBuffer({
      label: "Cell vertices",
      size: vertices.byteLength,
      usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST, // pass flags separated by |
    });

    // copy vertex data into the buffer
    device.queue.writeBuffer(vertexBuffer, /*bufferOffset=*/0, vertices);

    // define vertex data structure with `GPUVertexBufferLayout`
    const vertexBufferLayout = {
      // no of bytes to skip forward in the buffer when looking for next vertex
      arrayStride: 8, // 2x32bit floats -> 8 bytes
      attributes: [{
        format: "float32x2", // data format held by vertex
        offset: 0,
        shaderLocation: 0, // Position, see vertex shader 0-15
      }],
    };

    const cellShaderModule = device.createShaderModule({
      label: "Cell shader",
      code: `
        @vertex
        fn vertexNone() -> @builtin(position) vec4f {
          // this code renders nothing, since it points to 0, 0, 0, and it's being discarded
          return vec4f(0, 0, 0, 1); // (X, Y, Z, W)
        }

        @vertex
        fn vertexMain(@location(0) pos: vec2f) -> @builtin(position) vec4f {
          // uses @location(0) to match with vertexBufferLayout.attributes[0].shaderLocation
          // return vec4f(pos.x, pos.y, 0, 1);
          // since it's common to pass 2d vector into vec4f, there is a shorthand for that
          return vec4f(pos, 0, 1);
        }

        @fragment
        fn fragmentMain() -> @location(0) vec4f {
          return vec4f(1, 0, 0, 1); // (Red, Green, Blue, Alpha)
        }
      `
    });

    const cellPipeline = device.createRenderPipeline({
      label: "Cell pipeline",
      layout: "auto",
      vertex: {
        module: cellShaderModule,
        entryPoint: "vertexMain",
        buffers: [vertexBufferLayout]
      },
      fragment: {
        module: cellShaderModule,
        entryPoint: "fragmentMain",
        targets: [{
          format: canvasFormat
        }]
      }
    });


    pass.setPipeline(cellPipeline);
    pass.setVertexBuffer(0, vertexBuffer);
    pass.draw(vertices.length / 2); // 6 vertices

    pass.end();

    // // calling commands like beginRenderPass or pass.end() doesn't do anything
    // // it records the commands for the gpu to do later -> that's probably why we use this encoder

    device.queue.submit([encoder.finish()])


  </script>
</body>

</html>